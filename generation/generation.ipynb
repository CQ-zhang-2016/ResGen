{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use ResGen to generated molecules inside a specific protein pocket.\n",
    "Only the .pdb file (protein pocket) needed in the Generation process, or you can specify the original .pdb file and trunct\n",
    "the pocket around its original ligand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import warnings\n",
    "import os.path as osp\n",
    "from easydict import EasyDict\n",
    "from Bio import BiopythonWarning\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "from Bio.PDB.Selection import unfold_entities\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "sys.path.append('../../Res2Mol')\n",
    "from utils.feats.protein import get_protein_feature_v2\n",
    "from Bio.PDB import NeighborSearch, Selection\n",
    "from utils.protein_ligand import parse_sdf_file\n",
    "from utils.data import torchify_dict, ProteinLigandData\n",
    "#from feats.protein import \n",
    "from tqdm.auto import tqdm\n",
    "from models.ResGen import ResGen\n",
    "from utils.transforms import *\n",
    "from utils.misc import load_config, transform_data\n",
    "from utils.reconstruct import *\n",
    "from utils.datasets.res2mol import Res2MolDataset\n",
    "from utils.sample import get_init, get_next, logp_to_rank_prob\n",
    "from utils.sample import STATUS_FINISHED, STATUS_RUNNING\n",
    "\n",
    "def read_sdf(file):\n",
    "    supp = Chem.SDMolSupplier(file)\n",
    "    return [i for i in supp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdb_to_pocket_data(pdb_file, bbox_size=10.0, mol_file=None, center=None):\n",
    "    '''\n",
    "    use the sdf_file as the center \n",
    "    '''\n",
    "    if mol_file is not None:\n",
    "        prefix = mol_file.split('.')[-1]\n",
    "        if prefix == 'mol2':\n",
    "            center = Chem.MolFromMol2File(mol_file, sanitize=False).GetConformer().GetPositions()\n",
    "            center = np.array(center)\n",
    "        elif prefix == 'sdf':\n",
    "            supp = Chem.SDMolSupplier(mol_file, sanitize=False)\n",
    "            center = supp[0].GetConformer().GetPositions()\n",
    "        else:\n",
    "            print('The File type of Molecule is not support')\n",
    "    elif center is not None:\n",
    "        center = center\n",
    "    else:\n",
    "        print('You must specify the original ligand file or center')\n",
    "    warnings.simplefilter('ignore', BiopythonWarning)\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('target', pdb_file)[0]\n",
    "    atoms  = Selection.unfold_entities(structure, 'A')\n",
    "    ns = NeighborSearch(atoms)\n",
    "    close_residues= []\n",
    "    dist_threshold = bbox_size\n",
    "    for a in center:  \n",
    "        close_residues.extend(ns.search(a, dist_threshold, level='R'))\n",
    "    close_residues = Selection.uniqueify(close_residues)\n",
    "    protein_dict = get_protein_feature_v2(close_residues)\n",
    "\n",
    "    data = ProteinLigandData.from_protein_ligand_dicts(\n",
    "        protein_dict = protein_dict,\n",
    "        ligand_dict = {\n",
    "            'element': torch.empty([0,], dtype=torch.long),\n",
    "            'pos': torch.empty([0, 3], dtype=torch.float),\n",
    "            'atom_feature': torch.empty([0, 8], dtype=torch.float),\n",
    "            'bond_index': torch.empty([2, 0], dtype=torch.long),\n",
    "            'bond_type': torch.empty([0,], dtype=torch.long),\n",
    "        }\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', type=str, default='../configs/sample.yml')\n",
    "parser.add_argument('--outdir', type=str, default='../outputs')\n",
    "parser.add_argument('--device', type=str, default='cuda')\n",
    "parser.add_argument('--data_dir', type=str,default='../data/crossdocked_pocket10' )\n",
    "parser.add_argument('--check_point',type=str,default='../logs/use/57.pt')\n",
    "#args = parser.parse_args(['--data_id','2'])\n",
    "args = parser.parse_args([])\n",
    "config = load_config(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of parameters is 37.52M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the model and transform function (process the data again)\n",
    "contrastive_sampler = ContrastiveSample()\n",
    "ligand_featurizer = FeaturizeLigandAtom()\n",
    "transform = Compose([\n",
    "    RefineData(),\n",
    "    LigandCountNeighbors(),\n",
    "    ligand_featurizer\n",
    "])\n",
    "\n",
    "ckpt = torch.load(args.check_point, map_location=args.device)\n",
    "model = ResGen(\n",
    "    ckpt['config'].model, \n",
    "    num_classes = contrastive_sampler.num_elements,\n",
    "    num_bond_types = 3,\n",
    "    protein_res_feature_dim = (27,3),\n",
    "    ligand_atom_feature_dim = (13,1),\n",
    ").to(args.device)\n",
    "print('Num of parameters is {0:.4}M'.format(np.sum([p.numel() for p in model.parameters()]) /100000 ))\n",
    "model.load_state_dict(ckpt['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_file = './14gs_pocket.pdb'\n",
    "mol= read_sdf('./14gs_ligand.sdf')[0]\n",
    "atomCoords = mol.GetConformers()[0].GetPositions()\n",
    "data = pdb_to_pocket_data(pdb_file, center=atomCoords, bbox_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = LigandMaskAll()\n",
    "composer = Res2AtomComposer(27, ligand_featurizer.feature_dim, ckpt['config'].model.encoder.knn)\n",
    "masking = Compose([\n",
    "    mask, \n",
    "    composer\n",
    "])\n",
    "data = transform(data)\n",
    "data = transform_data(data, masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haotian/software/miniconda3/envs/carbon/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional probability threshold is too high. Change to 0.125000\n"
     ]
    }
   ],
   "source": [
    "np.seterr(invalid='ignore') \n",
    "pool = EasyDict({\n",
    "    'queue': [],\n",
    "    'failed': [],\n",
    "    'finished': [],\n",
    "    'duplicate': [],\n",
    "    'smiles': set(),\n",
    "})\n",
    "\n",
    "data = transform_data(deepcopy(data), masking)\n",
    "init_data_list = get_init(data.to(args.device),   # sample the initial atoms\n",
    "        model = model,\n",
    "        transform=composer,\n",
    "        threshold=config.sample.threshold\n",
    ")\n",
    "pool.queue = init_data_list\n",
    "#rint('Start to generate novel molecules with 3D conformation located in the protein pocket!')\n",
    "#print('The protein pocket is {}, init length is {}'.format(data.protein_filename, len(init_data_list)))\n",
    "global_step = 0 \n",
    "while len(pool.finished) < config.sample.num_samples:\n",
    "    global_step += 1\n",
    "    if global_step > config.sample.max_steps:\n",
    "        break\n",
    "    queue_size = len(pool.queue)\n",
    "    # # sample candidate new mols from each parent mol\n",
    "    queue_tmp = []\n",
    "    for data in pool.queue:\n",
    "        nexts = []\n",
    "        data_next_list = get_next(\n",
    "            data.to(args.device), \n",
    "            model = model,\n",
    "            transform = composer,\n",
    "            threshold = config.sample.threshold\n",
    "        )\n",
    "\n",
    "        for data_next in data_next_list:\n",
    "            if data_next.status == STATUS_FINISHED:\n",
    "                try:\n",
    "                    rdmol = reconstruct_from_generated_with_edges(data_next)\n",
    "                    data_next.rdmol = rdmol\n",
    "                    mol = Chem.MolFromSmiles(Chem.MolToSmiles(rdmol))\n",
    "                    smiles = Chem.MolToSmiles(mol)\n",
    "                    data_next.smiles = smiles\n",
    "                    if smiles in pool.smiles:\n",
    "                        #print('Duplicate molecule: %s' % smiles)\n",
    "                        pool.duplicate.append(data_next)\n",
    "                    elif '.' in smiles:\n",
    "                        #print('Failed molecule: %s' % smiles)\n",
    "                        pool.failed.append(data_next)\n",
    "                    else:   # Pass checks\n",
    "                        #print('Success: %s' % smiles)\n",
    "                        pool.finished.append(data_next)\n",
    "                        pool.smiles.add(smiles)\n",
    "                except MolReconsError:\n",
    "                    #print('Reconstruction error encountered.')\n",
    "                    pool.failed.append(data_next)\n",
    "            elif data_next.status == STATUS_RUNNING:\n",
    "                nexts.append(data_next)\n",
    "\n",
    "        queue_tmp += nexts\n",
    "    prob = logp_to_rank_prob(np.array([p.average_logp[2:] for p in queue_tmp]),)  # (logp_focal, logpdf_pos), logp_element, logp_hasatom, logp_bond\n",
    "    n_tmp = len(queue_tmp)\n",
    "    if n_tmp == 0:\n",
    "        print('This Generation has filures!')\n",
    "        break\n",
    "    else:\n",
    "        next_idx = np.random.choice(np.arange(n_tmp), p=prob, size=min(config.sample.beam_size, n_tmp), replace=False)\n",
    "    pool.queue = [queue_tmp[idx] for idx in next_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the mol file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_dir = './'\n",
    "sdf_file = os.path.join(sdf_dir,'test_gen.sdf')\n",
    "writer = Chem.SDWriter(sdf_file)\n",
    "for j in range(len(pool['finished'])):\n",
    "    writer.write(pool['finished'][j].rdmol)\n",
    "#print('{}th has been generated, {} saved'.format(i, sdf_file))\n",
    "writer.close()\n",
    "\n",
    "SDF_dir = './SDF'\n",
    "os.makedirs(SDF_dir, exist_ok=True)\n",
    "for j in range(len(pool['finished'])):\n",
    "    writer = Chem.SDWriter(SDF_dir+f'/{j}.sdf')\n",
    "    writer.write(pool['finished'][j].rdmol)\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('carbon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cb457098628399098f8244ea6d862b61e5b409c4fe20c91d3202c562013c713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
